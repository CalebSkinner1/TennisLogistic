---
title: "Tennis Logistic"
author: "Caleb Skinner"
date: "2023-07-28"
output:
  pdf_document:
    toc: yes
always_allow_html: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r for reading, include = FALSE}
library("knitr")
library("tidyverse")
library("jtools")
library("blorr")
library("ROCR")
library("caret")
library("scales")
library("roll")
library("lmtest")
library("flextable")
library("officer")
```

\newpage

# Overview

**Logistic regression** is a statistical model used to explain and analyze the relationship between one dependent (or response) variable and one or more independent (or predictor) variables. It follows many of the guidelines and procedures of simple linear regression *(link to other module)*. However, unlike some other regression models, logistic regression's dependent variable must be a binary variable with two outcomes. The independent variables can be any type of variable. Logistic regression uses the independent variables to predict the outcome of the dependent variable. Given several inputs, it assigns the probability of an outcome ranging from 0 to 1.

For example, a statistics teacher may be interested in predicting which of her students misses class on the day of a test. This is a binary categorical variable: a student either attends or is absent. The teacher can then look compile a list of predictor variables. This could include past attendance rates, homework grades, student GPA, day of the week of the test, illness history, etc. If she keeps track of this data, these variables will help her to predict the students that will miss class. Other logistic regression techniques will help her to identify which variables are important and the level of confidence in her predictions.

Logistic regression is commonly used to predict future outcomes and classify observations. It has numerous practical examples. It is widely used in the medical community to forecast the onset of diseases, in political science to predict elections, in marketing to understand consumer behavior, in banking to catch fraud, and in sports to predict victors.

## Tennis Overview

In this module, we'll analyze a sport that is full of dependent variables prime for logistic regression. Tennis's structure is full of binary scoring. For each point, game, set, and match, one player wins and one player loses. There is no third or partial option.

Tennis's scoring system can seem a bit complex for those unfamiliar. In short, two players play one **match**. In mens' tennis, one player must win three **sets** to win a match. In womens' tennis, one player must win two sets. The first player to six **games** (win by two) wins a set. If two players are tied at six games a piece, they play a **tiebreak** to determine the set winner. The first player to four **points** (win by two) wins a game. The points have unique values.

* 0 points: 0 (love)
* 1 point: 15
* 2 points: 30
* at least 3 points: 40

unless...

* leading by 1 point (ie 4 points to 3): AD (advantage)

One player **serves** to start the point (and the other **returns**) for an entire game, alternating serves each game with their opponent. Players have an advantage when they serve, and it is very significant when a player wins a game that their opponent serves. Winning a game as a returner is called a **break**. Conversly, winning a game as a server is called a **hold**.

Each week, there are single elimination tournaments for these players to compete in. We'll look at tennis's most famous tournament, Wimbledon. Wimbledon begins with 128 players in the men's and women's singles competitions. If the players win, they move on to the next round. After seven rounds, a champion is crowned.

This should be a thorough enough summary for you to understand the contents of the module. If you are still struggling to understand the rules of tennis, please see our data dictionary on the next page for clarity.

# Data

```{r wrangling}
set_flextable_defaults(
  font.size = 10, theme_fun = theme_zebra,
  padding = 6,
  background.color = "#EFEFEF")

w2022_matches_0 <- read_csv("tennis_slam_pointbypoint/2022-wimbledon-matches.csv") %>%
  select(match_id, player1, player2) %>%
  mutate(player1 = recode(player1,
                          "Tim Van Rijthoven" = "Tim van Rijthoven",
                          "Alex De Minaur" = "Alex de Minaur",
                          "Jan Lennard Struff" = "Jan-Lennard Struff",
                          "Albert Ramos Vinolas" = "Albert Ramos-Vinolas",
                          "Marc Andrea Huesler" = "Marc-Andrea Huesler",
                          "Felix Auger Aliassime" = "Felix Auger-Aliassime",
                          "Chun Hsin Tseng" = "Chun-Hsin Tseng",
                          "Botic Van De Zandschulp" = "Botic van de Zandschulp",
                          "Coco Vandeweghe" = "CoCo Vandeweghe",
                          "Alison Riske Amritraj" = "Alison Riske",
                          "Elena Gabriela Ruse" = "Elena-Gabriela Ruse",
                          "Ylena In Albon" = "Ylena In-Albon",
                          "Irina Camelia Begu" = "Irina-Camelia Begu"),
         player2 = recode(player2,
                          "Tim Van Rijthoven" = "Tim van Rijthoven",
                          "Alex De Minaur" = "Alex de Minaur",
                          "Jan Lennard Struff" = "Jan-Lennard Struff",
                          "Albert Ramos Vinolas" = "Albert Ramos-Vinolas",
                          "Marc Andrea Huesler" = "Marc-Andrea Huesler",
                          "Felix Auger Aliassime" = "Felix Auger-Aliassime",
                          "Chun Hsin Tseng" = "Chun-Hsin Tseng",
                          "Botic Van De Zandschulp" = "Botic van de Zandschulp",
                          "Coco Vandeweghe" = "CoCo Vandeweghe",
                          "Alison Riske Amritraj" = "Alison Riske",
                          "Elena Gabriela Ruse" = "Elena-Gabriela Ruse",
                          "Ylena In Albon" = "Ylena In-Albon",
                          "Irina Camelia Begu" = "Irina-Camelia Begu"))

w2022_rankings <- read_csv("tennis_slam_pointbypoint/2022-wimbledon-rankings.csv") %>% select(Player, Ranking) %>%
  mutate(Player = stringi::stri_trans_general(Player, "Latin-ASCII"),
         Player = recode(Player,
                         "Cori Gauff" = "Coco Gauff"))

w2022_matches <- w2022_matches_0 %>% dplyr::rename(Player = player1) %>%
  left_join(w2022_rankings, by = "Player") %>%
  mutate(Ranking = replace_na(Ranking, 600)) %>%
  dplyr::rename(player1 = Player,
         Player = player2,
         ranking1 = Ranking) %>%
  left_join(w2022_rankings, by = "Player") %>%
  mutate(Ranking = replace_na(Ranking, 600)) %>% 
  dplyr::rename(player2 = Player,
         ranking2 = Ranking)

# reading in data
w2022_0 <- read_csv("tennis_slam_pointbypoint/2022-wimbledon-points.csv",
                  col_types = cols(
                    PointNumber = col_double()))

# filtering out some data and removing excess variables
w2022_1 <- w2022_0 %>%
  filter((P1PointsWon + P2PointsWon) != 0) %>%
  
  #check below later, may want to add these columns back in. For now, we'll remove them for brevity
  select(-Rally, -P1FirstSrvIn, -P1FirstSrvWon, -P2FirstSrvIn, -P2FirstSrvWon, -ServeIndicator,
         -P1SecondSrvIn, -P1SecondSrvWon, -P2SecondSrvIn, -P2SecondSrvWon, -Speed_KMH,
         -P1ForcedError, -P2ForcedError, -Serve_Direction, -Winner_FH, -Winner_BH,
         -ServingTo, -P1TurningPoint, -P2TurningPoint, -WinnerType, -History, -P1Momentum, -P2Momentum,
         -contains("BreakPoint")) %>%
  
  # creating these identifiers
  mutate(
    tiebreak = if_else(GameNo == 13, 1, 0),
    set_winner = if_else(tiebreak == 1, GameWinner, SetWinner),
    retired = if_else(set_winner == 0 & match_id != lead(match_id), 1, 0), # cannot tell which player retired
    first_pt_set = if_else(GameNo == 1 & P1Score == 15 & P2Score == 0 |
                             GameNo == 1 & P1Score == 0 & P2Score == 15, 1, 0),
    last_pt_set = if_else(set_winner != 0 | retired != 0, 1, 0),
    match_pt = if_else(match_id != lead(match_id), 1, 0),
    p1_break_pt = lag((if_else(PointServer == 2 & P1Score == "AD", 1, 0) +
                         if_else(PointServer == 2 & P1Score == 40 & P2Score != 40 & P2Score != "AD", 1, 0))),
    p2_break_pt = lag((if_else(PointServer == 1 & P2Score == "AD", 1, 0) +
                         if_else(PointServer == 1 & P2Score == 40 & P1Score != 40 & P1Score != "AD", 1, 0))),
    p1_break_pt_won = if_else(p1_break_pt == 1 & PointWinner == 1, 1, 0),
    p2_break_pt_won = if_else(p2_break_pt == 1 & PointWinner == 2, 1, 0),
    p1_break_pt_missed = p1_break_pt - p1_break_pt_won,
    p2_break_pt_missed = p2_break_pt - p2_break_pt_won,
    pt_server1 = lead(PointServer),
    pt_server = pt_server1*2 - 3,
    status = case_when(
      P1GamesWon > P2GamesWon + 1 ~ "p1_break",
      P2GamesWon > P1GamesWon + 1 ~ "p2_break",
      P1GamesWon > P2GamesWon + 1 + pt_server ~ "p1_break",
      P2GamesWon > P1GamesWon + 1 + pt_server*-1 ~ "p2_break",
      .default = "no_break"),
    status = lag(status),
    status = if_else(lag(set_winner) > 0, "no_break", status),
    status = replace_na(status, "no_break"),
    p1_score = lag(P1Score),
    p2_score = lag(P2Score),
    p1_score = replace_na(p1_score, "0"),
    p2_score = replace_na(p2_score, "0"),
    p1_games = lag(P1GamesWon),
    p2_games = lag(P2GamesWon),
    p1_games = if_else(lag(set_winner) > 0, 0, p1_games),
    p2_games = if_else(lag(set_winner) > 0, 0, p2_games),
    p1_games = replace_na(p1_games, 0),
    p2_games = replace_na(p2_games, 0),
    p1_win_set = if_else(set_winner == 1, 1, 0),
    p2_win_set = if_else(set_winner == 2, 1, 0)) %>%
  group_by(match_id) %>%
  mutate(
    p1_sets = cumsum(p1_win_set),
    p2_sets = cumsum(p2_win_set),
    p1_sets = lag(p1_sets),
    p2_sets = lag(p2_sets),
    p1_sets = if_else(lag(match_pt) == 1, 0, p1_sets),
    p2_sets = if_else(lag(match_pt) == 1, 0, p2_sets),
    p1_sets = replace_na(p1_sets, 0),
    p2_sets = replace_na(p2_sets, 0),
  ) %>%
  ungroup() %>%
  mutate(
         # divides matches up between men's and women's
         sex = if_else(str_detect(match_id, "-1"), 1, 0),
         
         # removes NA from first line
         across(contains("break_pt"), ~replace_na(.,0))) %>%
  select(-pt_server1, -pt_server, -SetWinner, -P1Score, -P2Score, -contains("GamesWon"), -contains("win_set")) %>%
  left_join(w2022_matches, by = "match_id")

# function that calculates the mode
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]}

w2022 <- w2022_1 %>% filter(last_pt_set == 1) %>%
  group_by(match_id) %>%
  summarise(match_victor = getmode(set_winner),
            retired = sum(retired)) %>%
  filter(retired == 0) %>%
  select(-retired) %>%
  
  # adding walkover victors, checked winners online
  add_row(match_id = c("2022-wimbledon-1128", "2022-wimbledon-1207", "2022-wimbledon-2144", "2022-wimbledon-2146"),
          match_victor = c(1, 1, 2, 2)) %>%
  right_join(w2022_1, by = "match_id") %>%
  dplyr::rename(point_no = PointNumber,
         elapsed_time = ElapsedTime,
         set_no = SetNo,
         game_no = GameNo,
         server = PointServer,
         serve_no = ServeNumber,
         point_victor = PointWinner,
         game_winner = GameWinner,
         p1_points_won = P1PointsWon,
         p2_points_won = P2PointsWon,
         p1_ace = P1Ace,
         p2_ace = P2Ace,
         p1_winner = P1Winner,
         p2_winner = P2Winner,
         winner_shot_type = WinnerShotType,
         p1_double_fault = P1DoubleFault,
         p2_double_fault = P2DoubleFault,
         p1_unf_err = P1UnfErr,
         p2_unf_err = P2UnfErr,
         p1_net_pt = P1NetPoint,
         p2_net_pt = P2NetPoint,
         p1_net_pt_won = P1NetPointWon,
         p2_net_pt_won = P2NetPointWon,
         p1_distance_run = P1DistanceRun,
         p2_distance_run = P2DistanceRun,
         rally_count = RallyCount,
         speed_mph = Speed_MPH,
         serve_width = ServeWidth,
         serve_depth = ServeDepth,
         return_depth = ReturnDepth) %>% 
  
  # moving around all the column names into an order than makes sense
  relocate(contains("player"), .after = "match_id") %>%
  relocate("ranking1", .after = "player1") %>%
  relocate("ranking2", .after = "player2") %>%
  relocate("game_no", .after = "set_no") %>%
  relocate("server", .after = "game_no") %>%
  relocate("point_no", .after = "server") %>%
  relocate("status", .after = "point_no") %>% 
  relocate(contains("sets"), .after = "status") %>% 
  relocate(contains("games"), .after = "p2_sets") %>%
  relocate(contains("score"), .after = "p2_games") %>%
  relocate("point_victor", .after = "p2_score") %>%
  relocate(contains("points_won"), .after = "point_victor") %>%
  relocate("game_winner", .after = "p2_points_won") %>%
  relocate("set_winner", .after = "game_winner") %>%
  relocate("match_victor", .after = "set_winner") %>%
  relocate("serve_no", .after = "server") %>%
  relocate("winner_shot_type", .after = "p2_winner") %>%
  relocate("speed_mph", .before = "serve_width") %>%
  relocate(contains("break_pt"), .after = "p2_net_pt_won")

# after the point: game_winner, set_winner, point_victor, points_won
# before the point: elapsed_time, set_no, game_no, point_no, score, status, serve_no, games, sets
```

```{r setting up df}
point_w2022_0 <- w2022 %>%
  mutate(
    server = if_else(server == 2, 0, server),
    point_victor = if_else(point_victor == 2, 0, point_victor),
    game_winner = if_else(game_winner == 2, 0, game_winner),
    set_winner = if_else(set_winner == 2, 0, set_winner),
    set_winner = if_else(set_winner == 2, 0, set_winner),
    # lag_p1_distance = if_else(first_pt_set == 1, NA, lag(p1_distance_run)),
    # lag_p2_distance = if_else(first_pt_set == 1, NA, lag(p2_distance_run)),
    last_point_victor = if_else(point_no == 1, 0, lag(point_victor)), # technically this 0 should be an NA
    set_diff = p1_sets - p2_sets,
    # lag_p1_ace = if_else(lag(match_pt) == 0, lag(p1_ace), NA),
    # lag_p2_ace = if_else(lag(match_pt) == 0, lag(p2_ace), NA),
    # lag_p1_double_fault = if_else(lag(match_pt) == 0, lag(p1_double_fault), NA),
    # lag_p2_double_fault = if_else(lag(match_pt) == 0, lag(p2_double_fault), NA),
    pt_win_perc = if_else(set_no == 1 & game_no < 4, .5, lag(p1_points_won/(p2_points_won + p1_points_won))) * 100,
    rank_diff = ranking2 - ranking1,
    lastpt_p1_winner = if_else(point_no == 1, 0, lag(p1_winner)), # technically this 0 should be an NA
    lastpt_p2_winner = if_else(point_no == 1, 0, lag(p2_winner)), # technically this 0 should be an NA
    p1_serving_for_set = if_else(server == 1,
                                 if_else((p1_games == 5 & (p2_games < p1_games)) |
                                           (p1_games == 6 & (p2_games < p1_games)), 1, 0), 0),
    p2_serving_for_set = if_else(server == 0,
                                 if_else((p2_games == 5 & (p1_games < p2_games)) |
                                           (p2_games == 6 & (p1_games < p2_games)), 1, 0), 0),
    p1_serving_to_stay = if_else(server == 1,
                                 if_else((p2_games == 5 & (p1_games < p2_games)) |
                                           (p2_games == 6 & (p1_games < p2_games)), 1, 0), 0),
    p2_serving_to_stay = if_else(server == 0,
                                 if_else((p1_games == 5 & (p2_games < p1_games)) |
                                           (p1_games == 6 & (p2_games < p1_games)), 1, 0), 0)) %>%
  group_by(match_id) %>%
  mutate(
    p1_serves = cumsum(server),
    p2_serves = point_no - p1_serves,
    p1_serves_won = cumsum(point_victor*server),
    p2_serves_won = cumsum((point_victor - 1)*(server - 1)),
    p1_srv_win_perc = if_else(set_no == 1 & game_no < 7, .625, lag(p1_serves_won)/lag(p1_serves)) * 100,
    p2_srv_win_perc = if_else(set_no == 1 & game_no < 7, .625, lag(p2_serves_won)/lag(p2_serves)) * 100,
    p1_point = if_else(last_point_victor == 1, 1, 0),
    p2_point = if_else(last_point_victor == 0, 1, 0),
    p1_point_roll = roll_sum(p1_point, width = 25, min_obs = 1),
    p2_point_roll = roll_sum(p2_point, width = 25, min_obs = 1),
    roll_win_perc = if_else(point_no < 10, .5, p1_point_roll/(p1_point_roll + p2_point_roll)) * 100) %>%
  ungroup() %>%
  mutate(match_id = str_replace(match_id,"2022-wimbledon-", "")) %>%
  select(-contains("p1_point"), -contains("p2_point"))

prep_w2022 <- point_w2022_0 %>%
  select(match_id, player1, player2, rank_diff, match_victor, p1_sets, p2_sets, p1_games, p2_games, p1_score, p2_score, point_victor, server, pt_win_perc, roll_win_perc, set_diff, p1_break_pt, p2_break_pt, status, last_point_victor, lastpt_p1_winner, lastpt_p2_winner, p1_serving_for_set, p2_serving_for_set, p1_serving_to_stay, p2_serving_to_stay, sex, p1_srv_win_perc, p2_srv_win_perc, serve_no, point_no, tiebreak)
```

Our data includes both mens' and womens' singles tennis matches at Wimbledon in July, 2022. We have data from each point. A full data dictionary explaining each of our variables is below. The score of the match is recorded *before* the point takes place.

*I don't know to describe the 3rd and 4th digits of match_id. It just counts. They have no meaning*

```{r data dictionary}
dictionary_vars <- prep_w2022 %>%
  select(match_id, player1, player2, rank_diff, match_victor, p1_sets, p2_sets, p1_games, p2_games, p1_score, p2_score, point_victor, server, pt_win_perc, roll_win_perc, set_diff, p1_break_pt, p2_break_pt, status, last_point_victor, lastpt_p1_winner, lastpt_p2_winner, p1_serving_for_set, p2_serving_for_set, p1_serving_to_stay, p2_serving_to_stay) %>%
  colnames()

tibble(
  variables = dictionary_vars,
  explanation = c(
    "match identification; 1st digit: (1 = men's match, 2 = women's); 2nd digit: round (1-7)",
    "first and last name of the first player",
    "first and last name of the second player",
    "worldwide ranking of player 1 minus ranking of player 2",
    "winner of the match",
    "sets won by player 1",
    "sets won by player 2",
    "games won by player 1 in current set",
    "games won by player 2 in current set",
    "player 1's score within current game",
    "player 2's score within current game",
    "winner of the point",
    "server of the point",
    "percentage of points won by player 1 in match",
    "percentage of last 25 points won by player 1 in match",
    "sets won by player 1 minus sets won by player 2",
    "player 1 has a chance to \"break\" or win player 2's service game if they win the next point",
    "player 2 has a chance to \"break\" or win player 1's service game if they win the next point",
    "measurement of score in set",
    "winner of previous point",
    "player 1 hit an untouchable shot to win the previous point",
    "player 2 hit an untouchable shot to win the previous point",
    "player 1 is serving and has chance to win set",
    "player 2 is serving and has chance to win set",
    "player 1 is serving and could lose set",
    "player 2 is serving and could lose set"),
  example = c(
    str_c(prep_w2022$match_id[1], ", ", prep_w2022$match_id[45554], ", etc."),
    str_c(prep_w2022$player1[1], ", ", prep_w2022$player1[45554], ", etc."),
    str_c(prep_w2022$player2[1], ", ", prep_w2022$player2[45554], ", etc."),
    str_c(prep_w2022$rank_diff[1], ", ", prep_w2022$rank_diff[45554], ", etc."),
    "1 if player 1 wins, 0 if player 2 wins",
    "0, 1, or 2",
    "0, 1, or 2",
    "0, 1,...,6, etc.",
    "0, 1,...,6, etc.",
    "0 (love), 15, 30, 40, AD (advantage)",
    "0 (love), 15, 30, 40, AD (advantage)",
    "1 if player 1 wins, 0 if player 2 wins",
    "1 if player 1 serves, 0 if player 2 serves",
    "47, 51, etc. (first 3 games are set to 50)",
    "48, 52, etc. (first 9 points are set to 50)",
    "-2, -1, 0, 1, or 2",
    "0 or 1",
    "0 or 1",
    "\"no break\" if players are even, \"p1_break\" if player 1 has advantage, \"p2_break\" if player 2 has advantage",
    "1 if player 1 won previous point, 0 if player 2 won previous point",
    "0 or 1",
    "0 or 1",
    "0 or 1",
    "0 or 1",
    "0 or 1",
    "0 or 1")) %>%
  flextable() %>%
  padding(padding.right = 10, part = "body") %>% 
  align(align = "center", part = "header") %>%
  width(j = 1, width = 1.5) %>%
  width(j = 2, width = 3) %>%
  width(j = 3, width = 2.2) %>%
  border(border.top = fp_border(color = "pink"))
```

And here is an example slice of our data. *In ISLE, this will be the full data, allowing them to scroll at their leisure*

```{r}
prep_w2022 %>% select(any_of(dictionary_vars)) %>%
  slice(1:21) %>%
  flextable() %>%
  padding(padding = 0) %>%
  align(align = "center", part = "all") %>%
  width(j = c(2,3), width = .75) %>%
  fontsize(size = 6, part = "all") %>%
  width(j = c(1, 4, 10:11), width = .55) %>%
  width(j = 5, width = .75) %>%
  width(j = c(6:7), width = .45) %>%
  width(j = c(8:9), width = .55) %>%
  width(j = 12, width = .7) %>%
  width(j = 13, width = .4) %>% 
  width(j = 14, width = .9)
```

# Univariate Logistic Regression

Let's begin by using one predictor variable to predict one response variable.

## Binary Response Variables

The identifying factor of logistic regression is the binary response variable. A **binary response variable** is a dependent variable that only has two outcomes. Correlation with binary variables can be difficult to plot, understand, and interpret.

Let's begin by assessing the binary response variable match_victor. The result is 1 if the player wins and 0 if the player loses.

Let's try to predict the result of match_victor by using the discrete predictor variable rank_diff. Rank_diff is the difference between the two players' worldwide rankings. Below is a scatter-plot that visualizes their relationship. The players with superior rankings are located on the right-hand side, and the players with inferior rankings are on the left.

*I duplicated each match, by making each player an observation. Should I not have duplicated? This helps things by making the intercept 0 and making it more perfectly symmetrical. I didn't duplicate the later data sets*

```{r}
div <- c(48, 312)
vertical_lines <- c(seq(-div[2] + div[1], div[2] - div[1], div[1]))

ranking_victor <- w2022 %>%
  filter(last_pt_set == 1) %>%
  distinct(match_id, player1, ranking1, player2, ranking2, match_victor) %>%
  mutate(rank_diff = ranking2 - ranking1) %>%
  pivot_longer(c(player1, player2), names_to = "order", values_to = "player") %>%
  mutate(rank_diff = if_else(order == "player1", rank_diff, -rank_diff),
         match_victor = if_else(order == "player1" & match_victor == 1 | order == "player2" & match_victor == 2, 1, 0)) %>%
  # filter(str_detect(match_id, "wimbledon-11") | str_detect(match_id, "wimbledon-21")) %>%
  select(-ranking1, -ranking2, -order, -match_id)

ranking_victor %>%
  ggplot(aes(rank_diff, match_victor)) +
  geom_point(color = "indianred3", alpha = .7) +
  scale_x_continuous(limits = c(-div[2], div[2]), breaks = c(-300, -200, -100, 0, 100, 200, 300)) + 
  labs(y = "Victor", x = "Difference in Ranking")
```

The stack of points where match_victor (V) = 0 represent the ranking difference for losing players at Wimbledon. Conversely, the stack of points where match_victor (V) = 1 represent the ranking difference by victorious players at Wimbledon.

Would you estimate a player ranked 100 spots below his or her opponent wins his/her match? How confident would you be?

What about 50 spots below his or her opponent? 200? 25?

In simple linear regression, we place a linear trend line on the scatter plot so that our squared residuals are minimized. The **simple linear regression function** follows the formula:

* $E(Y) = \beta_{0} + \beta_{1}X_{1}$

where $\beta_{0}$ and $\beta_{1}$ are parameters and E(Y) is the **expected value** of Y, our response variable. Expected value is an important concept in regression with binary response variables. It represents the average value of the binary response variables given the predictors. These expected values will manifest in proportions ranging from 0 to 1.

For example, if, given a set of predictors, 8 out of 50 players win the match, then the expected value of match_victor (V) is $\frac{8}{50} = 0.16$. On average 16% of players win the match. In other words, there is a 16% probability that V = 1 given the set of predictors.

Let's see what a linear regression model looks like on our data. Remember, the linear trend line represents the expected value of match_victor for our data.

```{r}
ranking_victor %>%
  ggplot(aes(rank_diff, match_victor)) +
  geom_point(color = "indianred3", alpha = .7) +
  geom_smooth(color = "cadetblue3", method = "lm", level = NA) +
  scale_x_continuous(name = "Difference in Ranking", limits = c(-div[2], div[2]), breaks = c(-300, -200, -100, 0, 100, 200, 300)) +
  scale_y_continuous(name = "Victor E(V)", limits = c(-.25, 1.25), breaks = seq(0, 1, .25))
```

Where does the E(V) approach 0? Where does it approach 1?

What is the E(V) when the player is ranked 100 spots below his or her opponent? Is this close to what you estimated? What about 200 spots?

What is the E(V) when the player is ranked 300 spots below his or her opponent? Is this problematic?

How would you assess the linear regression model as a whole? Do the expected values match your expectations?

## Bins

The linear model is not a good fit for our data. It underestimates E(V) on both ends of the model. One way to improve the model is to separate the data into several groups called **bins**. We displayed the same visualization as before, but we added thirteen bins to help separate up the data.

```{r bins}
ranking_victor %>% ggplot(aes(rank_diff, match_victor)) +
  geom_point(color = "indianred3", alpha = .7) +
  labs(y = "Victor E(V)", x = "Difference in Ranking") +
  scale_x_continuous(name = "Difference in Ranking", limits = c(-div[2], div[2]), breaks = c(-300, -200, -100, 0, 100, 200, 300)) +
  geom_vline(xintercept = vertical_lines, color = "darkgrey")
```

We can find the proportion of victories within each bin and plot them. The dots in blue are the proportion of victories within each bin.

```{r}
means <- (vertical_lines - div[1]/2) %>% append(-min(.))
vertical_lines <- vertical_lines %>% append(c(min(.) - div[1], max(.) + div[1]))

ranking_victor %>%
  mutate(ranking_bin = ((as.numeric(cut(rank_diff, breaks = vertical_lines, labels = means)) - 7) * 48),
         ranking_bin = if_else(between(rank_diff, -312, -264), -288, ranking_bin)) %>%
  filter(!is.na(ranking_bin)) %>%
  group_by(ranking_bin) %>%
  summarise(victor_prop = mean(match_victor)) %>%
  bind_rows(ranking_victor) %>%
  ggplot() +
  geom_point(aes(rank_diff, match_victor), color = "indianred3", alpha = .7) +
  geom_point(aes(ranking_bin, victor_prop), color = "navyblue") + 
  scale_x_continuous(name = "Difference in Ranking", limits = c(-div[2], div[2]), breaks = c(-300, -200, -100, 0, 100, 200, 300)) +
  labs(y = "Victor E(V)")
```

The proportions of each bin form a curve. The shape of this curve is typically "S" shaped. The change in the proportion per unit decreases as the E(V) approaches 0 or 1. This is because the victory probability can never surpass the 0 to 1 range. As the players' ranking increases or decreases, eventually the E(V) must flatten.

## Intro to Logistic

There are several methods developed to model this "S" curve, but logistic regression is a popular choice, because it is mathematically easy to manipulate and it has meaningful and simple interpretations.

Logistic regression follows the logistic function:

* $E(Y) = \pi(x) = \displaystyle\frac{e^{\beta_{0} + \beta_{1}x}}{1 + e^{\beta_{0} + \beta_{1}x}}$

where $\pi(x)$ is the probability of y given x.

The **likelihood** is the probability of obtaining the observed set of data given the parameter estimates. Logistic regression uses an estimation method called **maximum likelihood**. It creates estimators $\hat{\beta_{0}}$ and $\hat{\beta_{1}}$ for the unknown true parameters $\beta_{0}$ and $\beta_{1}$ in order to maximize the likelihood.

It is common for logistic regression models to use the **log likelihood** (log of the likelihood), because it is easier to work with. This value will always be negative, and the closer the log likelihood is to 0, the more closely the estimators fit on the data.

Our logistic model provides us with estimates for our parameters $\beta_{0}$ and $\beta_{1}$.

```{r}
rank_glm <- glm(match_victor ~ rank_diff, family = binomial(link = "logit"), data = ranking_victor)
rank_beta <- rank_glm$coefficients %>% round(digits = 5)
```

* $\hat{\beta_{0}}$ (Intercept): `r rank_beta[1]`

* $\hat{\beta_{1}}$ (rank_diff): `r rank_beta[2]`

Thus,

$\hat{\pi}(x) = \displaystyle\frac{e^{0 + .01014x}}{1 + e^{0 + .01014x}}$

With our logistic function, we can predict a value for V given any value of x. Try a few below:

*student can enter a value of x and it should spit out a $\pi(x)$. I started with 50*

```{r}
x <- 50
Pi_x <- (exp(rank_beta[1] + rank_beta[2] * x)/(1 + exp(rank_beta[1] + rank_beta[2] * x))) %>% round(digits = 3)
```

$\hat{\pi}(x)$: `r Pi_x`

Let's see what a logistic regression would looks like mapped onto our data. The blue line represents the expected value of match_victor. It's our models predicted victory probability.

```{r}
ranking_victor %>%
  ggplot(aes(rank_diff, match_victor)) +
  geom_point(color = "indianred3", alpha = .7) +
  geom_smooth(color = "cadetblue3", method = "glm", se = FALSE, method.args = list(family = binomial)) +
  scale_x_continuous(limits = c(-div[2], div[2]), breaks = c(-300, -200, -100, 0, 100, 200, 300)) + 
  labs(y = "Victor E(V)", x = "Difference in Ranking")
```

Assess the logistic model. Can you see the "S" shaped curve? How well does it match the proportions? How does it differ from the linear model?

What is the proportion of victories for a player ranked 100 spots below his or her opponent? What about 50 spots below? 200?

## Residuals

However, like all models, the logistic function cannot perfectly predict the data. We can add the error term $\epsilon$ to our function to represent the difference between our estimation $\hat{\pi}(x)$ and the binary result V:

* V = $\hat{\pi}(x) + \epsilon$

A **residual** is the difference between the observed value (V) and the model's expected or predicted value ($\hat{\pi}(x)$). We can plot these values on a residual plot. The residuals are on the "logit" scale. We'll come back to that later.

```{r}
tibble(residuals = rank_glm$residuals,
       fitted = rank_glm$fitted.values,
       x = rank_glm$data$rank_diff,
       y = rank_glm$data$match_victor) %>%
  ggplot(aes(fitted, residuals)) +
  geom_point(color = "indianred3") +
  scale_y_continuous(name = "Residuals", limits = c(-10, 10), breaks = seq(-10, 10, 2.5)) +
  labs(x = "Predicted Values") +
  geom_hline(yintercept = 0, color = "darkgrey") +
  annotate("text", x = .3, y = -7.5, label = "V = 0", color = "darkgrey", size = 10) +
  annotate("text", x = .7, y = 7.5, label = "V = 1", color = "darkgrey", size = 10)
```

Each residual represents the error term $\hat{\epsilon}$. As the difference between the predicted values and actual values increase, the residuals increase. The values furthest from 0 represent the most unlikely events according to our model. Can you guess where those values reside on our scatter-plot?

## Interpretation

Interpreting the logistic model relies heavily on the understanding of odds. **Odds** are a ratio of the probability of a success and the probability of a failure (1 - success). We will often need to use this conversion in our interpretations. In our case:

* $odds(x) = \displaystyle\frac{\pi(x)}{1 - \pi(x)}$

which conveniently simplifies to:

* $odds(x) = e^{\beta_{0} + \beta_{1}x}$

Often, we want to find how these odds increase or decrease as our predictor changes. This is called the **odds ratio (OR)**. The odds ratio is calculated by the proportion of odds(x)/odds(x + 1).

* OR < 1 -- an increase in x decreases the odds of Y = 1.
* OR = 1 -- an increase in x does not impact the odds of Y = 1.
* OR > 1 -- an increase in x increases the odds of Y = 1.

Recall our $\hat{\beta_{0}}$ and $\hat{\beta_{1}}$. Can you find the player's odds of victory where x = 50? x = 51? Can you calculate their odds ratio?

```{r include = FALSE}
odds_ratio <- function(x1, x2){
  odds1 <- exp(rank_beta[1] + rank_beta[2] * x1)
  odds2 <- exp(rank_beta[1] + rank_beta[2] * x2)
  
  odds2/odds1
}

odds_ratio(99, 101)
```

*I made a function to calculate the odds ratio, should I let the student use it?*

Does the odds ratio change when x = 99 and x = 100?

Our model is logistic. This means that for each value of x, the odds ratio remains constant. We can calculate the **log odds** by applying a natural log (ln) to our odds function. This returns:

* log odds or "logit" = $g(x)$ = $\beta_{0} + \beta_{1}x$

This logit function is strikingly similar to the linear function, and it offers simple, linear-esque- interpretations. $\beta_{0}$ and $\beta_{1}$ are the intercept and slope of the log odds.

In our example,

* $\hat{\beta_{0}}$  = `r rank_beta[1]` is the estimated log-odds of victory when the difference in ranking is 0.

We can quickly solve for the odds by adding "e" to both sides.

* $e^{\hat{\beta_{0}}}$  = $e^{0}$ = 1 is the estimated odds of victory when the difference in ranking is 0. After converting our odds into a probability, we find that $\hat{\pi}(x)$ = 0.50.

Often, the intercept is meaningless or out of the natural range of the predictor. Consider a predictor like serve speed, height, or weight; these would never be zero. However, the slope is a crucial piece of analysis.

In our example,

* $\hat{\beta_{1}}$ = `r rank_beta[2]`. For each one unit increase in the difference in ranking, the log-odds of victory is estimated to increase by `r rank_beta[2]`.

Once again, we can provide helpful interpretations by adding an "e" to both sides.

* $e^{\hat{\beta_{1}}}$ = $e^{.01014}$ = `r round(exp(rank_beta[2]), digits = 5)`. The estimated odds of victory increase by `r percent(exp(rank_beta[2]) - 1, accuracy = .01)` for each unit increase in ranking difference.

# Multivariate Logistic Regression

*is this going to cause an issue with independence?*

*question on conditional effect in regression*

The logistic regression model is most useful when applying several predictors to a response variable. This can increase the model's predicting power and reduce the residuals. It can also allow the user to compare the strength of several predictors.

The multivariate logistic regression is adjusted to allow for more predictors:

* $E(Y) = \pi(x_{1}, x_{2},...x_{p}) + \epsilon = \displaystyle\frac{e^{\beta_{0} + \beta_{1}x_{1} + ... + \beta_{p}x_{p}}}{1 + e^{\beta_{0} + \beta_{1}x_{1} + ... + \beta_{p}x_{p}}} + \epsilon$

where $\pi(x_{1}, x_{2},..., x_{p})$ is the probability of y given the set of predictors x.

Once again, the logistic regression uses maximum likelihood estimates. Each of our unknown parameters $\hat{\beta_{0}}$, $\hat{\beta_{1}}$,..., $\hat{\beta_{p}}$ are estimated in order to maximize the probability of obtaining the observed set of data.

```{r}
victor_pw <- w2022 %>%
  # group_by(sex) %>% 
  summarise(
    victor_won = sum(point_victor == match_victor),
    loser_won = sum(point_victor != match_victor),
    victor_percent = percent(victor_won/(victor_won + loser_won), accuracy = .01),
    loser_percent = percent(loser_won/(victor_won + loser_won), accuracy = .01))
```

Earlier, we used the difference in ranking predictor to assess the match_victor binary response variable. Now, we will use a myriad of predictors to assess the point_victor binary response variable.

In tennis, there are hundreds of points played in a match. Often the difference between winning and losing can be only a few points. Over the course of Wimbledon in 2022, the losing player still won an average of `r victor_pw$loser_percent` of his or her points. But the circumstances of each point can be very different. Certain scores create more tense situations, and, often, the results of previous points can linger in players' minds. Players also typically enjoy a distinct advantage when they serve.

For this particular model, we are estimating the winner of a point, and we will use three predictor variables: $x_{1}$, $x_{2}$, and $x_{3}$.

* point_victor (Y): point_victor = 1 if player 1 wins the point, 0 if player 2 wins
* server ($x_{1}$): server = 1 if player 1 serves, 0 if player 2 serves
* pt_win_perc ($x_{2}$): percentage of the points won in the match at the start of the point (each unit is 1%)
* rank_diff ($x_{3}$): difference in the two players' worldwide rankings (player 2 - player 1)

It's important to note that our model is from the perspective of player 1. All point victory probabilities will be from his or her perspective. Solving for player 2's point probabilities will be the complement (1 - $\pi(x)$).

Let's see what the model produces and practice our interpretations. Our model yields the following estimators for our three parameters. They are interpreted in the same manner as in the univariate model.

```{r}
point_glm <- glm(point_victor ~ rank_diff + server + pt_win_perc,
                 family = binomial(link = "logit"), data = prep_w2022)

# summary(point_glm)

point_coeff <- point_glm$coefficients %>% round(digits = 4)
point_coeff %>% t() %>%
  as.data.frame() %>% flextable() %>%
  width(width = 1.2) %>%
  align(align = "center", part = "all")
```

The coefficients, $\hat{\beta_{j}}$, are the change in log-odds of victory (for player 1) given a one unit increase in the variable.

For instance, if the difference in ranking increases by 1 unit, then the estimated log-odds of victory increases by `r point_coeff[[2]] %>% format(scientific = FALSE)`. As with before, we can convert this to odds with e. In this case, for each unit increase in rank_diff, the estimated odds of victory increases by `r exp(point_coeff[[2]]) %>% round(digits = 4)`.

*do I capitalize server here?*

Server is an **indicator** variable. Indicator variables are binary; there are only two outcomes. This can make the interpretation of indicator variables seem a little different, because a 1-unit change completely flips the outcomes. Thus, for server, the coefficient directly compares the estimated log-odds of victory when player 1 serves to the estimated log-odds of victory when player 2 serves

Using the previous examples, interpret server and pt_win_perc. What are the changes in log-odds? Changes in odds? Are they meaningful?

The intercept is the log-odds of victory when all values are 0. What is this value? Is it meaningful?

*maybe add a note in isle: pt_win_perc is in percentage form. This means a 1 unit increase is actually 1%.

## Goodness of Fit

The estimators of our model give us important pieces of information about the relationship between our binary response variable and our predictors. They cannot, however, evaluate how well the model fits our data.

**Goodness of fit** assesses the extent in which our model's predicted values match the observed values. We can begin to compute a model's fit by measuring the model's residuals. A model **overestimates** the data if the observed values fall short of the expected values (producing a negative residual). A model **underestimates** the data if the observed values exceed the expected values (producing a positive residual).

Let's say our model gives a player a 70% chance to win a point. If he wins, the model has underestimated his chances and the observation returns a positive residual. If he loses, the model has overestimated his chances and the observation returns a negative residual.

Overall, we want these residuals to be as close to zero as possible. We also, however, want the model to be consistent in its fitness. We don't want a model that systematically overestimates certain types of observations and underestimates others. These systematic problems with the model would suggest a weakness in the model.

The Hosmer-Lemeshow goodness of fit test sorts the observations into ten equally sized groups or **deciles** by their predicted probabilities. Each decile will have similar values of $\hat{\pi}(x)$. The test compares the total expected values of each decile to the total observed values of each decile. Naturally, some of the deciles will be overestimated and some underestimated.

Here are the deciles of our point prediction model. The observed and expected are the number of points won in that category.

```{r, include = FALSE}
library("generalhoslem")

point_genhos <- logitgof(obs = prep_w2022$point_victor,
                         exp = fitted(point_glm))

detach("package:generalhoslem", unload = TRUE)
detach("package:MASS", unload = TRUE)

exp <- point_genhos$expected %>%
  as.data.frame() %>%
  pivot_wider(names_from = Var2, values_from = Freq)

point_deciles <- point_genhos$observed %>%
  as.data.frame() %>%
  pivot_wider(names_from = Var2, values_from = Freq) %>%
  left_join(exp, by = "cutyhat") %>%
  dplyr::rename(Observed = y1,
                Expected = yhat1,
                "Predictions Range" = cutyhat) %>%
  select(-y0, -yhat0) %>%
  mutate(Expected = round(Expected, digits = 1),
         Residual = Observed - Expected)
```

```{r}
flextable(point_deciles) %>%
  width(width = 1.3) %>%
  align(align = "center", part = "all") %>%
  set_caption(caption = "Point Prediction Deciles")
```

Notice that some of the deciles are overestimated and some are underestimated by the model.

The Hosmer-Lemeshow test evaluates these residuals and determines if they are large enough to suggest there are problems with our model. Our hypotheses are structured differently than traditional tests:

* $H_{0}$: is that the model fits the data.
* $H_{a}$: is that the model does not fit.

Our test statistic, $X^{2}$, can be solved with the following formula:

$X^{2} = \sum\frac{(observed - expected)^{2}}{expected}$

across our ten deciles.

If the deciles contain residuals that are far from zero, then we will have a large $X^{2}$. A large $X^{2}$ indicates a substantial problem with the model and suggests there are inconsistencies across its predictions. We would reject the null hypothesis that the model fits.

The Hosmer-Lemeshow test for our data:

* $X^{2}$: `r point_genhos$statistic`
* p-value: `r point_genhos$p.value %>% round(digits = 5)`

Since the p-value is larger than our alpha $\alpha$ of .05, we fail to reject our null hypothesis that the model fits.

Regardless of the overall fit of the model on the data, it is important to check the data for **influential** observations. Two important types of influential observations are outliers and leverage points. **Outliers** are observations with an extreme residual. They are points that the model struggled to predict. **High leverage** observations typically have uncommon characteristics. Their uniqueness causes them to have a strong impact on the model.

We don't have time to delve into the complexities of these points for now. If you are creating a logistic regression for yourself, it is important to check these observations and learn their characteristics. Sometimes, they hold interesting results or represent inaccurate data.

## Likelihood Ratio Test

Thus far, our model contains three predictors, but there are plenty of other variables we could add to improve the model. We also want to keep the model simple and avoid weak predictors. How do we decide when to add a variable and when to refrain?

When making this decision, it's helpful to imagine two distinct models:

1. Our *simple* model lacks the variable(s) in question.
2. Our *complex* model includes the variable(s) in question.

The **likelihood ratio test** compares the log likelihood between the two models. Recall that the log likelihood is a measure of the predictive ability of a model. If the difference between the two models is large enough, we can conclude that the variable(s) in question is significant in predicting the outcome.

In a simplified form, our hypothesis for the likelihood ratio test are as follows:

* $H_{0}$: the simple model is preferable.
* $H_{a}$: the complex model is preferable.

Let's say that we are considering adding a fourth variable, set_diff, to our model. We can use the likelihood ratio test to assess the difference in log likelihoods of our complex model with set_diff and our simple model without set_diff.

Below is our code and its output. You will need to reference it later.

```{r, echo = TRUE}
# producing simple model termed "simple"
simple <- glm(point_victor ~ rank_diff + server + pt_win_perc,
                 family = binomial(link = "logit"), data = prep_w2022)
# producing complex model termed "complex" - adding set_diff to equation
complex <- glm(point_victor ~ rank_diff + server + pt_win_perc + set_diff,
                 family = binomial(link = "logit"), data = prep_w2022)
# likelihood ratio test
lrtest(simple, complex)
```

The log likelihood for our simple model is -30254 and for our complex model is -30250. Our p-value is .009745, and this is less than our alpha of .05. Therefore, we should reject the null hypothesis and use the complex model.

We have several other variables that we'd like to check. Some of the variables are pairs, meaning that one applies to player 1 and one applies to player 2. Because there is no inherent difference between player 1 and player 2, it is best to keep the paired variables together in a model.

*thoughts? ^*

* p1_break_pt and p2_break_pt
* roll_win_perc
* status (categorical variable with three categories - interpretation may be advanced)
* last_point_victor
* lastpt_p1_winner and lastpt_p2_winner
* p1_serving_for_set and p2_serving_for_set
* p1_serving_to_stay and p2_serving_to_stay

*I am uncertain about the three "last" variables, because technically they make the data set smaller, because the first point of each match returns NA values. This will mess with likelihood ratio tests and such. I converted the NAs to 0, which is technically inaccurate...*

These are all variables that we have identified as potential predictors for our model. If you can't remember their meaning, then please check the data dictionary. Some variables are more complicated than others. Make sure to choose a variable that you can understand.

Using the code chunk below, create a simple and complex model and test the likelihood ratio of both of them. You can replicate our code from above. Copy the code exactly and then add your own variables using the + operator. Make sure the variables are spelled exactly like they are displayed. Repeat this process several times until you think you've found the best model for our data.

*here is an example of what the student would do*

```{r}
simple <- glm(point_victor ~ rank_diff + server + pt_win_perc + set_diff,
                 family = binomial(link = "logit"), data = prep_w2022)
complex <- glm(point_victor ~ rank_diff + server + pt_win_perc + set_diff + last_point_victor,
                 family = binomial(link = "logit"), data = prep_w2022)
lrtest(simple, complex)
```

Once you've evaluated the test, interpret it and decide if we have enough evidence to reject our null hypothesis.

The likelihood ratio test can also be used to test the significance of the entire model. It follows a similar to what we have described and is an important and common use. However, we don't have time to cover it in this module.

## Testing Individual Parameters

The likelihood ratio test assesses the strength of the entire model, but sometimes we want to focus our attention on one variable.

The **Wald test** assesses the effect of one predictor on the binary response variable. The test "controls" for the influence of each other variable in the model; the effect of all other variables in the model are held constant. If the variable's slope $\beta_{j}$ is significantly far from 0, then we can conclude that there is an effect on the response variable.

Our hypotheses for the Wald test:

* $H_{0}: \beta_{j} = 0$ (no effect)
* $H_{a}: \beta_{j} \neq 0$ (some effect)

Our test statistic Z is calculated simply with the formula:

* Z = $\displaystyle\frac{\hat{\beta_{j}}}{SE(\hat{\beta_{j}})}$

Our statistical software will display the Wald test results for each parameter in a table. Let's look specifically at the pt_win_perc variable in our new model (with set_diff) to see if its effect is significant.

*should I display just the one variable or all of them here?*

```{r}
point_glm <- glm(point_victor ~ rank_diff + server + pt_win_perc + set_diff,
                 family = binomial(link = "logit"), data = prep_w2022)

wald_table <- function(glm){
  summary(glm)[["coefficients"]] %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  as_tibble() %>%
  dplyr::rename("p.value" = "Pr(>|z|)") %>%
  mutate(across(Estimate:"z value", ~round(.x, digits = 4)),
         p.value = if_else(p.value > .00001, as.character(round(p.value, digits = 4)), if_else(p.value == 0, as.character(0), format(p.value, format = "e", digits = 2)))) %>%
  flextable() %>%
  align(align = "center", part = "all") %>%
  set_caption(caption = "Point Parameters Wald test") %>%
  width(j = 1, width = 1.35)
}

point_glm %>% wald_table()
```

Wald's test statistic for pt_win_perc is 6.732 and the p-value approaches 0. Our p-value is less than our alpha of .05, so we can reject our null hypothesis and conclude that pt_win_perc has some effect. While controlling for the difference in ranking, the server, and the set score, the proportion of points won in the match has some effect on the player's probability of winning a point.

All four of our predictors have statistically significant effects on point_victor, but this isn't true across every one of our potential variables. If a variable appears to have insignificant effects, we would consider removing it from our model. Before removing a predictor, we should check the likelihood ratio test to confirm our findings.

Try out different combinations of variables for yourself. Which variables are always significant? How does the significance of some predictors vary across different models.

*student will be given a coding chunk. This will allow them to test out different variables*

```{r}
stu_wald <- glm(point_victor ~ rank_diff + server + pt_win_perc + set_diff + p1_break_pt + p2_break_pt + roll_win_perc + status + last_point_victor + lastpt_p1_winner + lastpt_p2_winner + p1_serving_for_set + p2_serving_for_set + p1_serving_to_stay + p2_serving_to_stay,
            family = binomial(link = "logit"), data = prep_w2022)

stu_wald %>% wald_table()
```

Interpret at least one new predictor.

The Wald test can occasionally yield different results than the likelihood ratio test, because they use different methodologies. It is generally preferable to defer to the likelihood ratio test's results.

### Confidence Intervals

Each of our coefficients $\hat{\beta_{j}}$ are estimates of the true unknown parameters $\beta_{j}$. The Wald test also provides **confidence intervals** to help quantify the uncertainty of these estimates. Our Wald confidence intervals are calculated with the following formula:

* 95% confidence interval of $\beta_{j}$ = $\hat{\beta_{j}} \pm z_{1-\frac{\alpha}{2}}*\hat{SE}(\hat{\beta_{j}})$

With 95% confidence, we can assert that our true parameter lies within this interval. These intervals can help us to interpret the magnitude and certainty of our parameters effect. A large confidence interval would indicate that we are uncertain of the parameter's true effect on the response variable.

Let's look to our model. We'll interpret the intercept, pt_win_perc, and server for you, and then ask you to do the same for a few predictor variables. Remember, the coefficients represent the change in log-odds of victory for player 1.

```{r}
indiv_conf <- function(glm, type) {
  df <- summ(glm, confint = TRUE)[["coeftable"]] %>%
    as.data.frame() %>%
    rownames_to_column(var = "Parameter") %>%
    as_tibble() %>%
    select(-"z val.", -p) %>%
    mutate(across(where(is.numeric), ~round(.x, digits = 4))) %>%
    dplyr::rename("Estimate" = "Est.") %>%
    relocate(Estimate, .before = "97.5%")
  
  df_exp <- df %>% mutate(across(where(is.numeric), ~exp(.x)),
                          across(where(is.numeric), ~round(.x, digits = 4)))
  
  if(type == "log-odds") {return(df)}
  if(type == "odds-ratio"){return(df_exp)}
  if(type != "log-odds" & type != "odds-ratio"){print("Error!")}
}

log_odds <- indiv_conf(point_glm, "log-odds")

flextable(log_odds) %>%
  align(align = "center", part = "all") %>%
  set_caption(caption = "Log-Odds Confidence Intervals") %>%
  width(j = 1, width = 1.3)
```

Log-odds are difficult to interpret. For more applicable interpretations, we will convert each of our intervals into esimated odds-ratio by applying "e" to each value.

```{r}
odds <- indiv_conf(point_glm, "odds-ratio")

flextable(odds) %>%
  align(align = "center", part = "all") %>%
  set_caption(caption = "Odds-Ratio Confidence Intervals") %>%
  width(j = 1, width = 1.3)
```

Intercept: The estimated odds of victory *for player 1* are `r odds$Estimate[1]` when all variables are at 0. In this scenario, the two players have the same ranking, player 2 is serving, player 1 has won 0% of the points so far in the match, and the set-score is tied. The odds may be as low as `r odds$"2.5%"[1]` or as high as `r odds$"97.5%"[1]` with 95% confidence.

*capitalize these variables?*

pt_win_perc: The estimated odds of victory *for player 1* increase by `r (odds$Estimate[4] - 1) %>% percent(accuracy = .01)` for each 1-unit increase in the percentage of points won by player 1 in the match, controlling for the difference in ranking of the players, the server, and the set score. The increase may be as low as `r (odds$"2.5%"[4] - 1) %>% percent(accuracy = .01)` or as a high as `r (odds$"97.5%"[4] - 1) %>% percent(accuracy = .01)` with 95% confidence.

Server: The estimated odds of victory *for player 1* increase by `r (odds$Estimate[3] - 1) %>% percent(accuracy = .01)` when player 1 serves, controlling for the difference in ranking of the players, the percentage of points won thus far in the match, and the set score. The increase may be as low as `r (odds$"2.5%"[3] - 1) %>% percent(accuracy = .01)` or as a high as `r (odds$"97.5%"[3] - 1) %>% percent(accuracy = .01)` with 95% confidence.

Using our format, interpret a few of the confidence of intervals in your own model. We'll allow you to create your own model using our variables. We'll print out the odds-ratios for each variable. Remember, an odds-ratio above 1 indicates a positive effect on the result variable, and an odds-ratio below 1 indicates a negative effect on the result variable.

*guess some of the student models*

```{r}
stu_conf_int <- glm(point_victor ~ rank_diff + server + pt_win_perc + set_diff + p1_break_pt + p2_break_pt + roll_win_perc + status + lastpt_p1_winner + lastpt_p2_winner + p1_serving_for_set + p2_serving_for_set + p1_serving_to_stay + p2_serving_to_stay,
            family = binomial(link = "logit"), data = prep_w2022)

stu_wald %>% indiv_conf("odds-ratio") %>%
  flextable() %>%
  align(align = "center", part = "all") %>%
  set_caption(caption = "Odds-Ratio Confidence Intervals") %>%
  width(j = 1, width = 1.35)
```

Interpret three of the above parameters. Which parameters have the largest confidence intervals? Which parameters' are you most uncertain about their effect on the point_victor?

## Predictions

Using our full model, we can now predict the probability that a player will win a point in match given our set of predictors. We can also construct a confidence interval for this prediction by combining the variance of each of the parameters. Our estimate for the log-odds of Y:

* $\hat{g}(x) = \hat{\beta_{0}} + \hat{\beta_{1}}x_{1} + ... + \hat{\beta_{p}}x_{p}$

And our confidence intervals of the log-odds:

* $\hat{g}(x) \pm z_{1 - \frac{\alpha}{2}}\hat{SE}(\hat{g}(x))$

We can convert out log-odds into more probabilities for interpretation by:

* $\hat{p}(x) = \displaystyle\frac{e^{\hat{g}(x)}}{1 + e^{\hat{g}(x)}}$

Let's pick an interesting match to analyze as we assess our model's predictive abilities. We've compiled a list of the longest matches of Wimbledon 2022. The first ten are the longest men's matches and the second ten are the longest women's matches.

```{r}
womens <- w2022 %>%
  filter(match_pt == 1, retired == 0, sex == 0) %>%
  select(match_id, player1, player2, p1_points_won, p2_points_won, point_no) %>%
  arrange(desc(point_no)) %>%
  slice(1:10)

w2022 %>%
  filter(match_pt == 1, retired == 0) %>%
  select(match_id, player1, player2, p1_points_won, p2_points_won, point_no) %>%
  arrange(desc(point_no)) %>%
  slice(1:10) %>%
  bind_rows(womens) %>%
  dplyr::rename("total_points" = point_no,
                p1_pts_won = p1_points_won,
                p2_pts_won = p2_points_won) %>%
  mutate(match_id = str_replace(match_id, "2022-wimbledon-", "")) %>%
  flextable() %>%
  align(align = "center", part = "all") %>%
  set_caption(caption = "Longest Wimbledon Matches") %>%
  width(width = 1.05) %>%
  width(j = c(2,3), width = 1.3)
```

The longest match of Wimbledon 2022 featured Belgian David Goffin and American Frances Tiafoe. The data set designated Goffin as player 1 and Tiafoe as player 2. Goffin won a tightly contested match by three sets to two. The match lasted over four hours and 30 minutes. Let's pick five interesting points and calculate our model's predicted probability of victory for each of them. All probabilities will be from the perspective of Goffin, because he is player 1.

We've tabulated our five points with each of our parameters present.

```{r}
# creates parameter df
parameters <- function(points, variables, match){
  prep_w2022 %>% select(match_id, point_no, player1, player2, any_of(variables)) %>%
    filter(str_detect(match_id, match), point_no %in% points) %>%
    mutate(across(contains("perc"), ~round(.x, digits = 3))) %>%
    select(-match_id)}

# creates parameter flextable
parameters_flex <- function(points, variables, match){
  df <- parameters(points, variables, match)
  
  player1 <- df$player1[1]
  player2 <- df$player2[1]
  
  df %>%
    select(-point_victor, -player1, -player2) %>%
    flextable() %>%
    align(align = "center", part = "all") %>%
    set_caption(caption = str_c(player1, " vs. ", player2, ": Predictor Values")) %>%
    width(width = 1)
}

gf_pts <- c(1, 106, 107, 270, 402)
gf_var <- c("rank_diff", "server", "pt_win_perc", "set_diff", "point_victor")
gf_mch <- "1403"

goffoe_parameters <- parameters(gf_pts, gf_var, gf_mch)

parameters_flex(gf_pts, gf_var, gf_mch)
```

We'll calculate the probability Goffin wins the first point "by hand". This table below will help us remember our model's estimates.

```{r}
point_coeff <- point_glm$coefficients %>% round(digits = 4) %>% format(scientific = FALSE)
point_coeff %>% t() %>%
  as.data.frame() %>% flextable() %>%
  width(width = 1.2) %>%
  align(align = "center", part = "all") %>%
  set_caption(caption = "Parameter Estimates")
```

Log-odds of victory for Goffin in point 1:

* $\hat{g}(1)$ = `r point_coeff[[1]]` + `r point_coeff[[2]]`(-30) + `r point_coeff[[3]]`(0) + `r point_coeff[[4]]`(50) + `r point_coeff[[5]]`(0) = -0.5368

Probability:

* $\hat{p}(x) = \displaystyle\frac{e^{-0.5368}}{1 + e^{-0.5368)}}$ = .3691

Let's see what our predictions are for all five of our points.

```{r}
# creates prediction df
point_estimates <- function(points, variables, match, glm){
  df <- parameters(points, variables, match)
  
  coeff <- glm$coefficients
  
  df %>%
    mutate(
      log_odds = coeff[[1]] + coeff[[2]] * rank_diff + coeff[[3]] * server + coeff[[4]] * pt_win_perc + coeff[[5]] * set_diff,
      se = predict(glm, df, se.fit = TRUE)$se.fit,
      lower_lo = log_odds - 1.96 * se,
      upper_lo = log_odds + 1.96 * se
      ) %>%
    select(-se) %>% 
    mutate(across(log_odds:upper_lo, ~exp(.x)/(1 + exp(.x)), .names = "{col}_prob")) %>%
    dplyr::rename("prediction" = log_odds_prob,
                  "2.5%" = lower_lo_prob,
                  "97.5%" = upper_lo_prob) %>%
    select(-lower_lo, -upper_lo, -player1, -player2, -any_of(variables), point_victor) %>%
    mutate(across(log_odds:`97.5%`, ~round(.x, digits = 4))) %>%
    relocate(`2.5%`, .before = prediction) %>%
    relocate(point_victor, .after = last_col())
}

# creates prediction flextable
predictions_flex <- function(points, variables, match, glm) {
  df <- point_estimates(points, variables, match, glm)
  
  df2 <- parameters(points, variables, match)
  player1 <- df2$player1[1]
  player2 <- df2$player2[1]
  
  df %>%
    flextable() %>%
    align(align = "center", part = "all") %>%
    set_caption(caption = str_c(player1, " vs. ", player2, ": Predictions")) %>%
    width(j = 6, width = 1)
}

goffoe_predictions <- point_estimates(gf_pts, gf_var, gf_mch, point_glm)
predictions_flex(gf_pts, gf_var, gf_mch, point_glm)
```

Given our predictors, we estimate the probability of victory for Goffin in the first point is `r goffoe_predictions$prediction[1] %>% percent(accuracy = .01)`. This probability of victory is as low as `r goffoe_predictions$"2.5%"[1] %>% percent(accuracy = .01)` and as high as `r goffoe_predictions$"97.5%"[1] %>% percent(accuracy = .01)` with 95% certainty.

In more statistical language, we are 95% confident that the true probability of winning the point given these parameters is between `r goffoe_predictions$"2.5%"[1] %>% percent(accuracy = .01)` and `r goffoe_predictions$"97.5%"[1] %>% percent(accuracy = .01)`.

*is this right? ^*

Pick a few points yourself to assess. We'll let you pick a match that interests you and a few point numbers. The first player listed in the title is player 1.

*student selects model, match, and points they'd like to assess. I chose a model with every variable, if we are wanting a pdf version of this, we should select a model that does not go off the page lol*

```{r student inputs}
# student selects model
stu_glm <- glm(point_victor ~ rank_diff + server + pt_win_perc + set_diff + p1_break_pt + p2_break_pt + roll_win_perc + status + lastpt_p1_winner + lastpt_p2_winner + last_point_victor + p1_serving_for_set + p2_serving_for_set + p1_serving_to_stay + p2_serving_to_stay,
            family = binomial(link = "logit"), data = prep_w2022)

# student selects interesting points
stu_points <- c(51,100,111,171,191)

# student selects match
stu_match <- "1701"
```

Below are the parameters of the `r length(stu_points)` points you chose. Feel free to adjust your choices.

```{r}
# create variables from model
stu_variables <- stu_glm$model %>% colnames() %>% as_vector()

parameters_flex(stu_points, stu_variables, stu_match)
```

Given the values of the predictor variables at each of those points, below is the prediction table.

```{r}
predictions_flex(stu_points, stu_variables, stu_match, stu_glm)
```

Using the values from the table interpret at least three points. Which points did the model predict well? Which points did the model predict poorly?

In a table, we can only see a few of the points. Often, it can be helpful to visualize a lot of the model's predictions at once. We can plot the model's predictions of an entire match and compare the predictions with the actual results. The following plot visualizes an entire match at Wimbledon. Feel free to change the match to whichever match_id interests you. You can also adjust the model and see how the predictions change.

*I really think this visualization below is the coolest thing ever. It is kinda tangentially applicable but so awesome*

```{r plot function}
fit_plot <- function(df_edit, match, df_log) {
  vlines_0 <- w2022 %>% filter(str_detect(match_id, match), set_winner != 0) %>% select(point_no)
  vlines <- vlines_0 %>% slice(1:(n()-1)) %>% pull() + .5
  vlines_0 <- vlines_0 %>% pull()
  set_scores <- w2022 %>%
    filter(str_detect(match_id, match), set_winner != 0) %>%
    mutate(p1_games = p1_games + if_else(point_victor == 1, 1, 0),
           p2_games = p2_games + if_else(point_victor == 2, 1, 0)) %>% select(p1_games, p2_games)
  
  player1 <- w2022 %>% filter(str_detect(match_id, match)) %>% select(player1) %>% distinct() %>% pull()
  player2 <- w2022 %>% filter(str_detect(match_id, match)) %>% select(player2) %>% distinct() %>% pull()
  
  df <- tibble(fitted = df_log$fitted.values,
               point = df_edit$point_no,
               match_id = df_edit$match_id,
               player1 = w2022$player1,
               player2 = w2022$player2,
               winner = factor(if_else(df_edit$point_victor == 1, player1, player2)),
               residual = df_log$residuals,
               break_pt = factor(w2022$p1_break_pt_won + w2022$p2_break_pt_won)) %>%
    filter(str_detect(match_id, match))
  
  midpt <- (max(df$fitted) + min(df$fitted))/2
  
  df %>% ggplot(aes(point, fitted)) +
    geom_point(aes(color = winner, shape = break_pt, size = break_pt)) +
    geom_vline(xintercept = vlines) +
    scale_size_discrete(name = "Break", range = c(3,5)) +
    scale_shape_manual(name = "Break", values = c(16,8)) +
    scale_color_discrete(name = "Point Winner") +
    labs(y = str_c(player1), x = "Point", title = str_c(player1, " vs. ", player2)) +
    scale_y_continuous(breaks = seq(.2, .8, .05), sec.axis = sec_axis(name = str_c(player2), ~ 1 - ., breaks = seq(.2, .8, .05))) +
    annotate("text", x = (vlines_0[1] - .5)/2, y = midpt, label = str_c(set_scores[1,][1],"-",set_scores[1,][2]), color = "darkgrey", size = 7.5) +
    annotate("text", x = (vlines_0[2] - vlines_0[1] - .5)/2 + vlines_0[1], y = midpt, label = str_c(set_scores[2,][1],"-",set_scores[2,][2]), color = "darkgrey", size = 7.5) +
    annotate("text", x = (vlines_0[3] - vlines_0[2] - .5)/2 + vlines_0[2], y = midpt, label = str_c(set_scores[3,][1],"-",set_scores[3,][2]), color = "darkgrey", size = 7.5) +
    annotate("text", x = (vlines_0[4] - vlines_0[3] -.5)/2 + vlines_0[3], y = midpt, label = str_c(set_scores[4,][1],"-",set_scores[4,][2]), color = "darkgrey", size = 7.5) +
    annotate("text", x = (vlines_0[5] - vlines_0[4] -.5)/2 + vlines_0[4], y = midpt, label = str_c(set_scores[5,][1],"-",set_scores[5,][2]), color = "darkgrey", size = 7.5)
}
```

```{r}
# student can change model
stu_glm <- glm(point_victor ~ rank_diff + server + pt_win_perc + set_diff + p1_break_pt + p2_break_pt + roll_win_perc + status + lastpt_p1_winner + lastpt_p2_winner + last_point_victor + p1_serving_for_set + p2_serving_for_set + p1_serving_to_stay + p2_serving_to_stay,
               family = binomial(link = "logit"), data = prep_w2022)

# student can change match
stu_match <- "1701"

prep_w2022 %>% fit_plot(stu_match, stu_glm)
```

*I think we might want to skip this part?*

# Attribution

Jeff Sackman's license:

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Dataset" property="dct:title" rel="dct:type">Tennis databases, files, and algorithms</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://www.tennisabstract.com/" property="cc:attributionName" rel="cc:attributionURL">Jeff Sackmann / Tennis Abstract</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.<br />Based on a work at <a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/JeffSackmann" rel="dct:source">https://github.com/JeffSackmann</a>.

